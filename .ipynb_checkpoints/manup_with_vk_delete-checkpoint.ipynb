{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import pandas_gbq as gbq\n",
    "import requests\n",
    "import time\n",
    "\n",
    "project_id = 'arctic-task-238719'\n",
    "private_key='arctic-task-238719-e6a1c5fe056b.json'\n",
    "credentials = service_account.Credentials.from_service_account_file('./arctic-task-238719-e6a1c5fe056b.json')\n",
    "\n",
    "gbq.context.credentials = credentials\n",
    "gbq.context.project = project_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузить посты из определенной группе \n",
    "def upload_post_from_vk_group(username,group_id):\n",
    "    token = 'e7a79876e7a79876e7a79876e9e7ce3561ee7a7e7a79876bb0457d3e507797f75821138'\n",
    "    version = 5.92\n",
    "    count = 100\n",
    "    offset = 0\n",
    "    all_posts = []\n",
    "    x = 100\n",
    "    df = pd.DataFrame(columns=['group_id','group_name', 'post_id','post','annotation','keywords'])\n",
    "    response= requests.get('https://api.vk.com/method/groups.getById',\n",
    "                            params={\n",
    "                                'group_id': group_id,\n",
    "                                'access_token': token,\n",
    "                                'v': version,\n",
    "                                \n",
    "                            }\n",
    "                            )\n",
    "\n",
    "    group_name=response.json()['response'][0]['name']\n",
    "    k=100\n",
    "    while (k==100):\n",
    "        start_time = time.time()\n",
    "        if group_id.isnumeric():\n",
    "            response = requests.get('https://api.vk.com/method/wall.get',\n",
    "                                    params={\n",
    "                                        'access_token': token,\n",
    "                                        'v': version,\n",
    "                                        'owner_id': '-'+group_id,\n",
    "                                        'count': count,\n",
    "                                        'offset':offset\n",
    "                                    }\n",
    "                                    )\n",
    "        else:\n",
    "            response = requests.get('https://api.vk.com/method/wall.get',\n",
    "                                    params={\n",
    "                                        'access_token': token,\n",
    "                                        'v': version,\n",
    "                                        'domain': group_id,\n",
    "                                        'count': count,\n",
    "                                        'offset':offset\n",
    "                                    }\n",
    "                                    )\n",
    "        data = response.json()['response']['items']\n",
    "        offset += 100\n",
    "        k=len(data)\n",
    "        j=0\n",
    "        for i in range(k):\n",
    "            annotation = 'annotation'\n",
    "            keywords = 'keywords'\n",
    "            post_id = data[i]['id']\n",
    "            post = data[i]['text']\n",
    "            if post!='':\n",
    "                df.loc[j] = [group_id,group_name,int(post_id), post,annotation,keywords]\n",
    "                j+=1\n",
    "        gbq.to_gbq(df,'dataset.vk_storage_'+username, project_id , if_exists = 'append')\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "# upload_post_from_vk_group('kirill','192959150')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалить из биб для vk группу по id \n",
    "def delete_row_group_from_userlibrary(username,group_id):\n",
    "    credentials = service_account.Credentials.from_service_account_file('./arctic-task-238719-e6a1c5fe056b.json')\n",
    "\n",
    "    client = bigquery.Client(project='arctic-task-238719',credentials=credentials)\n",
    "    \n",
    "    Query=f'DELETE  FROM dataset.vk_storage_{username} WHERE group_id = \\'{group_id}\\''\n",
    "    query_job = client.query(Query)\n",
    "    \n",
    "\n",
    "delete_row_group_from_userlibrary('kirill','meaning_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалить из личной биб со статьями по названию и автору\n",
    "def delete_row_article_from_userlibrary(username,author,title):\n",
    "    credentials = service_account.Credentials.from_service_account_file('./arctic-task-238719-e6a1c5fe056b.json')\n",
    "\n",
    "    client = bigquery.Client(project='arctic-task-238719',credentials=credentials)\n",
    "    Query=f'DELETE  FROM dataset.{username} WHERE author like \\'%{author}%\\' and title likw \\'%{title}%\\' '\n",
    "    query_job = client.query(Query)\n",
    "\n",
    "# title='Рассеяние энергии механических колебаний в мягких ферромагнитных материалах в зависимости от фазы колебаний'\n",
    "# delete_row_article_from_userlibrary('kirill','Глотова Людмила Сергеевна',title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "from google.oauth2 import service_account\n",
    "project_id = 'arctic-task-238719'\n",
    "private_key='arctic-task-238719-e6a1c5fe056b.json'\n",
    "import json\n",
    "from google.cloud import bigquery\n",
    "credentials = service_account.Credentials.from_service_account_file('./arctic-task-238719-e6a1c5fe056b.json')\n",
    "from pandas.io import gbq\n",
    "stops = set(stopwords.words(\"english\")) | set(stopwords.words(\"russian\"))\n",
    "import pandas as pd\n",
    "morph=pymorphy2.MorphAnalyzer()\n",
    "stemmer=SnowballStemmer('russian')\n",
    "def search_in_user_vk_library(username,word='',mode='post'):\n",
    "    \n",
    "    if mode=='post_from_group':\n",
    "        group_name,word=word.split(',')\n",
    "        \n",
    "        word = re.sub(\"[^а-яА-Яa-zA-Z0-9]\", \" \", word)\n",
    "        words = word.lower().split()\n",
    "        words = [w for w in words if not w in stops]\n",
    "        words = [stemmer.stem(w) for w in words]\n",
    "        if words=='':\n",
    "            return \"некорректный ввод\"\n",
    "        \n",
    "        Query = f'SELECT * FROM dataset.vk_storage_{username}  WHERE group_name=\\'{group_name}\\' and (post LIKE \\''\n",
    "        for word in words:\n",
    "            Query+='%{}'.format(word)\n",
    "        Query +='%\\' or post LIKE \\' '\n",
    "        flag=True\n",
    "        for word in words:\n",
    "            if flag==True:\n",
    "                Query+='%{}'.format(word.capitalize())\n",
    "                flag=False\n",
    "            else:\n",
    "                Query+='%{}'.format(word)\n",
    "        Query +='%\\')'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    word = re.sub(\"[^а-яА-Яa-zA-Z0-9]\", \" \", word)\n",
    "    words = word.lower().split()\n",
    "    words = [w for w in words if not w in stops]\n",
    "    words = [stemmer.stem(w) for w in words]\n",
    "    if words=='':\n",
    "        return \"некорректный ввод\"\n",
    "\n",
    "    if mode=='post':\n",
    "        Query = f'SELECT * FROM dataset.vk_storage_{username}  WHERE post LIKE \\''\n",
    "        for word in words:\n",
    "            Query+='%{}'.format(word)\n",
    "        Query +='%\\' or post LIKE \\' '\n",
    "        flag=True\n",
    "        for word in words:\n",
    "            if flag==True:\n",
    "                Query+='%{}'.format(word.capitalize())\n",
    "                flag=False\n",
    "            else:\n",
    "                Query+='%{}'.format(word)\n",
    "        Query +='%\\''\n",
    "          \n",
    "    df = gbq.read_gbq(Query, project_id, credentials=credentials)\n",
    "    \n",
    "    result = df.values.tolist()\n",
    "    return result\n",
    "\n",
    "# search(mode='kws',word='физика')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: The default value for dialect is changing to \"standard\" in a future version. Pass in dialect=\"legacy\" or set pandas_gbq.context.dialect=\"legacy\" to disable this warning.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['hghg', '192959150'], ['Data Science', 'datascience']]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def show_all_groups(username):\n",
    "    \n",
    "    Query = f'SELECT  group_name,group_id FROM dataset.vk_storage_{username}  group by group_name,group_id'\n",
    "    df = gbq.read_gbq(Query, project_id, credentials=credentials)\n",
    "    result = df.values.tolist()\n",
    "    \n",
    "    return  result\n",
    "\n",
    "# search(mode='kws',word='физика')\n",
    "\n",
    "show_all_groups('kirill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_user_library(username):\n",
    "    \n",
    "    Query = f'SELECT authors,title FROM dataset.{username}'\n",
    "    df = gbq.read_gbq(Query, project_id, credentials=credentials)\n",
    "    result = df.values.tolist()\n",
    "    \n",
    "    return  result\n",
    "\n",
    "# search(mode='kws',word='физика')\n",
    "\n",
    "# show_user_library(username='kirill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "GenericGBQException",
     "evalue": "Reason: 400 Syntax error: Unexpected \")\" at [1:33]\n\n(job ID: 6f71eb1f-9c60-44df-a07a-d2a9cb7491af)\n\n                                              -----Query Job SQL Follows-----                                              \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:SELECT group_id,MAX(CAST(post_id)) as last FROM dataset.vk_storage_kirill where group_id='192959150' group by group_id\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/2019-2-Atom-Backend-K-Kondratenya/venv/lib/python3.6/site-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36m_download_results\u001b[0;34m(self, query_job, max_results, progress_bar_type)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0;31m# Get the table schema, so that we can list rows.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2019-2-Atom-Backend-K-Kondratenya/venv/lib/python3.6/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout)\u001b[0m\n\u001b[1;32m   3195\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3196\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2019-2-Atom-Backend-K-Kondratenya/venv/lib/python3.6/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;31m# TODO: modify PollingFuture so it can pass a retry argument to done().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_AsyncJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2019-2-Atom-Backend-K-Kondratenya/venv/lib/python3.6/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 Syntax error: Unexpected \")\" at [1:33]\n\n(job ID: 6f71eb1f-9c60-44df-a07a-d2a9cb7491af)\n\n                                              -----Query Job SQL Follows-----                                              \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:SELECT group_id,MAX(CAST(post_id)) as last FROM dataset.vk_storage_kirill where group_id='192959150' group by group_id\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mGenericGBQException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ad32fe62348f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# search(mode='kws',word='физика')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdata_about_group_for_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kirill'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'192959150'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-ad32fe62348f>\u001b[0m in \u001b[0;36mdata_about_group_for_update\u001b[0;34m(username, group_id, credentials)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mQuery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'SELECT group_id,MAX(CAST(post_id)) as last FROM dataset.vk_storage_{username} where group_id=\\'{group_id}\\' group by group_id'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gbq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2019-2-Atom-Backend-K-Kondratenya/venv/lib/python3.6/site-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36mread_gbq\u001b[0;34m(query, project_id, index_col, col_order, reauth, auth_local_webserver, dialect, location, configuration, credentials, use_bqstorage_api, max_results, verbose, private_key, progress_bar_type)\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0mconfiguration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m     )\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2019-2-Atom-Backend-K-Kondratenya/venv/lib/python3.6/site-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36mrun_query\u001b[0;34m(self, query, max_results, progress_bar_type, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mquery_reply\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         )\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2019-2-Atom-Backend-K-Kondratenya/venv/lib/python3.6/site-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36m_download_results\u001b[0;34m(self, query_job, max_results, progress_bar_type)\u001b[0m\n\u001b[1;32m    556\u001b[0m             )\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_error\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_http_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/2019-2-Atom-Backend-K-Kondratenya/venv/lib/python3.6/site-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36mprocess_http_error\u001b[0;34m(ex)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;31m# <https://cloud.google.com/bigquery/troubleshooting-errors>`__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mGenericGBQException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reason: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     def run_query(\n",
      "\u001b[0;31mGenericGBQException\u001b[0m: Reason: 400 Syntax error: Unexpected \")\" at [1:33]\n\n(job ID: 6f71eb1f-9c60-44df-a07a-d2a9cb7491af)\n\n                                              -----Query Job SQL Follows-----                                              \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:SELECT group_id,MAX(CAST(post_id)) as last FROM dataset.vk_storage_kirill where group_id='192959150' group by group_id\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |"
     ]
    }
   ],
   "source": [
    "\n",
    "def data_about_group_for_update(username,group_id,credentials=credentials):\n",
    "    \n",
    "    Query = f'SELECT group_id,MAX(CAST(post_id) as last FROM dataset.vk_storage_{username} where group_id=\\'{group_id}\\' group by group_id'\n",
    "    df = gbq.read_gbq(Query, project_id, credentials=credentials)\n",
    "    result = df['last'].values.tolist()\n",
    "    \n",
    "    return  result\n",
    "\n",
    "# search(mode='kws',word='физика')\n",
    "\n",
    "data_about_group_for_update(username='kirill',group_id='192959150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_post_from_vk_group(username,group_id,credentials):\n",
    "    last_post_id = data_about_group_for_update(username,group_id,credentials)[0]\n",
    "    \n",
    "    token = 'e7a79876e7a79876e7a79876e9e7ce3561ee7a7e7a79876bb0457d3e507797f75821138'\n",
    "    version = 5.92\n",
    "    count = 100\n",
    "    offset = 0\n",
    "    all_posts = []\n",
    "    x = 100\n",
    "    df = pd.DataFrame(columns=['group_id','group_name', 'post_id','post','annotation','keywords'])\n",
    "    response= requests.get('https://api.vk.com/method/groups.getById',\n",
    "                            params={\n",
    "                                'group_id': group_id,\n",
    "                                'access_token': token,\n",
    "                                'v': version,\n",
    "                                \n",
    "                            }\n",
    "                            )\n",
    "\n",
    "    group_name=response.json()['response'][0]['name']\n",
    "    k=100\n",
    "    while (k==100):\n",
    "        start_time = time.time()\n",
    "        if group_id.isnumeric():\n",
    "            response = requests.get('https://api.vk.com/method/wall.get',\n",
    "                                    params={\n",
    "                                        'access_token': token,\n",
    "                                        'v': version,\n",
    "                                        'owner_id': '-'+group_id,\n",
    "                                        'count': count,\n",
    "                                        'offset':offset\n",
    "                                    }\n",
    "                                    )\n",
    "        else:\n",
    "            response = requests.get('https://api.vk.com/method/wall.get',\n",
    "                                    params={\n",
    "                                        'access_token': token,\n",
    "                                        'v': version,\n",
    "                                        'domain': group_id,\n",
    "                                        'count': count,\n",
    "                                        'offset':offset\n",
    "                                    }\n",
    "                                    )\n",
    "        data = response.json()['response']['items']\n",
    "        \n",
    "        k=len(data)\n",
    "        offset += 100\n",
    "        j=0\n",
    "        for i in range(len(data)):\n",
    "            annotation = 'annotation'\n",
    "            keywords = 'keywords'\n",
    "            post_id = data[i]['id']\n",
    "            post = data[i]['text']\n",
    "            if post!='' and int(post_id)!=last_post_id:\n",
    "                df.loc[j] = [group_id,group_name,int(post_id), post,annotation,keywords]\n",
    "                j+=1\n",
    "            elif int(post_id)==last_post_id:\n",
    "                break\n",
    "            \n",
    "        \n",
    "        if len(df)!=0:\n",
    "            gbq.to_gbq(df,'dataset.vk_storage_'+username, project_id , if_exists = 'append')\n",
    "        time.sleep(0.1)\n",
    "\n",
    "# update_post_from_vk_group('kirill','192959150',credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import pandas_gbq as gbq\n",
    "\n",
    "project_id = 'arctic-task-238719'\n",
    "private_key='arctic-task-238719-e6a1c5fe056b.json'\n",
    "credentials = service_account.Credentials.from_service_account_file('./arctic-task-238719-e6a1c5fe056b.json')\n",
    "\n",
    "gbq.context.credentials = credentials\n",
    "gbq.context.project = project_id\n",
    "\n",
    "\n",
    "def upload_user_bd(list_of_lists,username):\n",
    "    try:\n",
    "        df = pd.DataFrame(list_of_lists, columns=['author','title','keywords'])\n",
    "        gbq.to_gbq(df,'dataset.'+username, project_id , if_exists = 'append'   )\n",
    "    return True\n",
    "    \n",
    "    except:\n",
    "        return -1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
